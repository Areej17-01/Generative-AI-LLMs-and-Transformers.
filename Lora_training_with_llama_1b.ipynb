{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPBtYQ29bTWsRNHlDW41m9h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Areej17-01/Generative-AI-LLMs-and-Transformers./blob/main/Lora_training_with_llama_1b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGMKy7biKPfC",
        "outputId": "93183124-f48c-452e-b66a-bb6c48b70947"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Feb  9 16:25:28 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import torch\n",
        "# Check so there is a gpu available, a T4(free tier) is enough to run this notebook\n",
        "assert (torch.cuda.is_available()==True)\n",
        "\n",
        "\n",
        "!pip  install --no-build-isolation axolotl[flash-attn,deepspeed]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ho7gRUdFKo4r",
        "outputId": "d76f50b8-128f-4038-a36e-08412b82b298"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: axolotl[deepspeed,flash-attn] in /usr/local/lib/python3.11/dist-packages (0.6.0)\n",
            "Requirement already satisfied: bitsandbytes==0.45.0 in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (0.45.0)\n",
            "Requirement already satisfied: triton>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (3.1.0)\n",
            "Requirement already satisfied: liger-kernel==0.4.2 in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (0.4.2)\n",
            "Requirement already satisfied: packaging==23.2 in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (23.2)\n",
            "Requirement already satisfied: peft==0.14.0 in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (0.14.0)\n",
            "Requirement already satisfied: transformers>=4.46.3 in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (4.48.2)\n",
            "Requirement already satisfied: tokenizers>=0.20.1 in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (0.21.0)\n",
            "Requirement already satisfied: accelerate==1.2.0 in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (1.2.0)\n",
            "Requirement already satisfied: datasets==3.1.0 in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (3.1.0)\n",
            "Requirement already satisfied: pydantic==2.6.3 in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (2.6.3)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (2.4.0)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (0.7.0)\n",
            "Requirement already satisfied: PyYAML>=6.0 in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (2.32.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (0.2.0)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (0.19.6)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (0.8.0)\n",
            "Requirement already satisfied: optimum==1.16.2 in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (1.16.2)\n",
            "Requirement already satisfied: hf-transfer in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (0.1.9)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (0.4.6)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (0.61.0)\n",
            "Requirement already satisfied: numpy<=2.0.1,>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (1.26.4)\n",
            "Requirement already satisfied: evaluate==0.4.1 in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (0.4.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn==1.4.2 in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (1.4.2)\n",
            "Requirement already satisfied: nvidia-ml-py==12.560.30 in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (12.560.30)\n",
            "Requirement already satisfied: art in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (6.4)\n",
            "Requirement already satisfied: gradio==3.50.2 in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (3.50.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (2.18.0)\n",
            "Requirement already satisfied: python-dotenv==1.0.1 in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (1.0.1)\n",
            "Requirement already satisfied: s3fs>=2024.5.0 in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (2024.9.0)\n",
            "Requirement already satisfied: gcsfs>=2024.5.0 in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (2024.9.0.post1)\n",
            "Requirement already satisfied: trl==0.12.1 in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (0.12.1)\n",
            "Requirement already satisfied: zstandard==0.22.0 in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (0.22.0)\n",
            "Requirement already satisfied: fastcore in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (1.7.29)\n",
            "Requirement already satisfied: lm-eval==0.4.4 in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (0.4.4)\n",
            "Requirement already satisfied: langdetect==1.0.9 in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (1.0.9)\n",
            "Requirement already satisfied: immutabledict==4.2.0 in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (4.2.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.13.2 in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (4.13.2)\n",
            "Requirement already satisfied: torchao==0.5.0 in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (0.5.0)\n",
            "Requirement already satisfied: schedulefree==1.3.0 in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (1.3)\n",
            "Requirement already satisfied: torch==2.5.1+cu124 in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (2.5.1+cu124)\n",
            "Requirement already satisfied: xformers==0.0.28.post3 in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (0.0.28.post3)\n",
            "Requirement already satisfied: deepspeed==0.16.1 in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (0.16.1)\n",
            "Requirement already satisfied: deepspeed-kernels in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (0.0.1.dev1698255861)\n",
            "Requirement already satisfied: flash-attn==2.7.0.post2 in /usr/local/lib/python3.11/dist-packages (from axolotl[deepspeed,flash-attn]) (2.7.0.post2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==1.2.0->axolotl[deepspeed,flash-attn]) (5.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.2.0->axolotl[deepspeed,flash-attn]) (0.28.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.2.0->axolotl[deepspeed,flash-attn]) (0.5.2)\n",
            "Requirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes==0.45.0->axolotl[deepspeed,flash-attn]) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets==3.1.0->axolotl[deepspeed,flash-attn]) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.1.0->axolotl[deepspeed,flash-attn]) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.1.0->axolotl[deepspeed,flash-attn]) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==3.1.0->axolotl[deepspeed,flash-attn]) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets==3.1.0->axolotl[deepspeed,flash-attn]) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets==3.1.0->axolotl[deepspeed,flash-attn]) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets==3.1.0->axolotl[deepspeed,flash-attn]) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets==3.1.0->axolotl[deepspeed,flash-attn]) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==3.1.0->axolotl[deepspeed,flash-attn]) (3.11.11)\n",
            "Requirement already satisfied: hjson in /usr/local/lib/python3.11/dist-packages (from deepspeed==0.16.1->axolotl[deepspeed,flash-attn]) (3.1.0)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from deepspeed==0.16.1->axolotl[deepspeed,flash-attn]) (1.1.0)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from deepspeed==0.16.1->axolotl[deepspeed,flash-attn]) (1.11.1.3)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from deepspeed==0.16.1->axolotl[deepspeed,flash-attn]) (9.0.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.11/dist-packages (from evaluate==0.4.1->axolotl[deepspeed,flash-attn]) (0.18.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2->axolotl[deepspeed,flash-attn]) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2->axolotl[deepspeed,flash-attn]) (5.5.0)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2->axolotl[deepspeed,flash-attn]) (0.115.8)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2->axolotl[deepspeed,flash-attn]) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==0.6.1 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2->axolotl[deepspeed,flash-attn]) (0.6.1)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2->axolotl[deepspeed,flash-attn]) (0.28.1)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2->axolotl[deepspeed,flash-attn]) (6.5.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2->axolotl[deepspeed,flash-attn]) (3.1.5)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2->axolotl[deepspeed,flash-attn]) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2->axolotl[deepspeed,flash-attn]) (3.10.0)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2->axolotl[deepspeed,flash-attn]) (3.10.15)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2->axolotl[deepspeed,flash-attn]) (10.4.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2->axolotl[deepspeed,flash-attn]) (0.25.1)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2->axolotl[deepspeed,flash-attn]) (0.0.20)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2->axolotl[deepspeed,flash-attn]) (2.10.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2->axolotl[deepspeed,flash-attn]) (0.34.0)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2->axolotl[deepspeed,flash-attn]) (11.0.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect==1.0.9->axolotl[deepspeed,flash-attn]) (1.17.0)\n",
            "Requirement already satisfied: jsonlines in /usr/local/lib/python3.11/dist-packages (from lm-eval==0.4.4->axolotl[deepspeed,flash-attn]) (4.0.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from lm-eval==0.4.4->axolotl[deepspeed,flash-attn]) (2.10.2)\n",
            "Requirement already satisfied: pybind11>=2.6.2 in /usr/local/lib/python3.11/dist-packages (from lm-eval==0.4.4->axolotl[deepspeed,flash-attn]) (2.13.6)\n",
            "Requirement already satisfied: pytablewriter in /usr/local/lib/python3.11/dist-packages (from lm-eval==0.4.4->axolotl[deepspeed,flash-attn]) (1.2.1)\n",
            "Requirement already satisfied: rouge-score>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from lm-eval==0.4.4->axolotl[deepspeed,flash-attn]) (0.1.2)\n",
            "Requirement already satisfied: sacrebleu>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from lm-eval==0.4.4->axolotl[deepspeed,flash-attn]) (2.5.1)\n",
            "Requirement already satisfied: sqlitedict in /usr/local/lib/python3.11/dist-packages (from lm-eval==0.4.4->axolotl[deepspeed,flash-attn]) (2.1.0)\n",
            "Requirement already satisfied: tqdm-multiprocess in /usr/local/lib/python3.11/dist-packages (from lm-eval==0.4.4->axolotl[deepspeed,flash-attn]) (0.0.11)\n",
            "Requirement already satisfied: word2number in /usr/local/lib/python3.11/dist-packages (from lm-eval==0.4.4->axolotl[deepspeed,flash-attn]) (1.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from lm-eval==0.4.4->axolotl[deepspeed,flash-attn]) (10.6.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from optimum==1.16.2->axolotl[deepspeed,flash-attn]) (15.0.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from optimum==1.16.2->axolotl[deepspeed,flash-attn]) (1.13.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic==2.6.3->axolotl[deepspeed,flash-attn]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.11/dist-packages (from pydantic==2.6.3->axolotl[deepspeed,flash-attn]) (2.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.4.2->axolotl[deepspeed,flash-attn]) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.4.2->axolotl[deepspeed,flash-attn]) (3.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1+cu124->axolotl[deepspeed,flash-attn]) (3.4.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1+cu124->axolotl[deepspeed,flash-attn]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1+cu124->axolotl[deepspeed,flash-attn]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1+cu124->axolotl[deepspeed,flash-attn]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1+cu124->axolotl[deepspeed,flash-attn]) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1+cu124->axolotl[deepspeed,flash-attn]) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1+cu124->axolotl[deepspeed,flash-attn]) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1+cu124->axolotl[deepspeed,flash-attn]) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1+cu124->axolotl[deepspeed,flash-attn]) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1+cu124->axolotl[deepspeed,flash-attn]) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1+cu124->axolotl[deepspeed,flash-attn]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1+cu124->axolotl[deepspeed,flash-attn]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1+cu124->axolotl[deepspeed,flash-attn]) (12.4.127)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl==0.12.1->axolotl[deepspeed,flash-attn]) (13.9.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->optimum==1.16.2->axolotl[deepspeed,flash-attn]) (1.3.0)\n",
            "Requirement already satisfied: decorator>4.1.2 in /usr/local/lib/python3.11/dist-packages (from gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (4.4.2)\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.11/dist-packages (from gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.11/dist-packages (from gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (1.2.1)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.11/dist-packages (from gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (2.19.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->axolotl[deepspeed,flash-attn]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->axolotl[deepspeed,flash-attn]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->axolotl[deepspeed,flash-attn]) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->axolotl[deepspeed,flash-attn]) (2025.1.31)\n",
            "Requirement already satisfied: aiobotocore<3.0.0,>=2.5.4 in /usr/local/lib/python3.11/dist-packages (from s3fs>=2024.5.0->axolotl[deepspeed,flash-attn]) (2.19.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.46.3->axolotl[deepspeed,flash-attn]) (2024.11.6)\n",
            "Requirement already satisfied: cmake>=3.24 in /usr/local/lib/python3.11/dist-packages (from deepspeed-kernels->axolotl[deepspeed,flash-attn]) (3.31.4)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire->axolotl[deepspeed,flash-attn]) (2.5.0)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->axolotl[deepspeed,flash-attn]) (0.44.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->axolotl[deepspeed,flash-attn]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->axolotl[deepspeed,flash-attn]) (1.70.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->axolotl[deepspeed,flash-attn]) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->axolotl[deepspeed,flash-attn]) (4.25.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->axolotl[deepspeed,flash-attn]) (75.1.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->axolotl[deepspeed,flash-attn]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->axolotl[deepspeed,flash-attn]) (3.1.3)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb->axolotl[deepspeed,flash-attn]) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb->axolotl[deepspeed,flash-attn]) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->axolotl[deepspeed,flash-attn]) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->axolotl[deepspeed,flash-attn]) (4.3.6)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->axolotl[deepspeed,flash-attn]) (2.20.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb->axolotl[deepspeed,flash-attn]) (1.3.4)\n",
            "Requirement already satisfied: aioitertools<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2024.5.0->axolotl[deepspeed,flash-attn]) (0.12.0)\n",
            "Requirement already satisfied: botocore<1.36.4,>=1.36.0 in /usr/local/lib/python3.11/dist-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2024.5.0->axolotl[deepspeed,flash-attn]) (1.36.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2024.5.0->axolotl[deepspeed,flash-attn]) (2.8.2)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2024.5.0->axolotl[deepspeed,flash-attn]) (1.0.1)\n",
            "Requirement already satisfied: multidict<7.0.0,>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2024.5.0->axolotl[deepspeed,flash-attn]) (6.1.0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in /usr/local/lib/python3.11/dist-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2024.5.0->axolotl[deepspeed,flash-attn]) (1.17.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.1.0->axolotl[deepspeed,flash-attn]) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.1.0->axolotl[deepspeed,flash-attn]) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.1.0->axolotl[deepspeed,flash-attn]) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.1.0->axolotl[deepspeed,flash-attn]) (1.5.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.1.0->axolotl[deepspeed,flash-attn]) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.1.0->axolotl[deepspeed,flash-attn]) (1.18.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6.0,>=4.2.0->gradio==3.50.2->axolotl[deepspeed,flash-attn]) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6.0,>=4.2.0->gradio==3.50.2->axolotl[deepspeed,flash-attn]) (1.25.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->axolotl[deepspeed,flash-attn]) (4.0.12)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.2->gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.2->gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.2->gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (4.9)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==3.50.2->axolotl[deepspeed,flash-attn]) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==3.50.2->axolotl[deepspeed,flash-attn]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==3.50.2->axolotl[deepspeed,flash-attn]) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==3.50.2->axolotl[deepspeed,flash-attn]) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==3.50.2->axolotl[deepspeed,flash-attn]) (3.2.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.1.0->axolotl[deepspeed,flash-attn]) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.1.0->axolotl[deepspeed,flash-attn]) (2025.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score>=0.0.4->lm-eval==0.4.4->axolotl[deepspeed,flash-attn]) (3.9.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from sacrebleu>=1.5.0->lm-eval==0.4.4->axolotl[deepspeed,flash-attn]) (3.1.1)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu>=1.5.0->lm-eval==0.4.4->axolotl[deepspeed,flash-attn]) (0.9.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu>=1.5.0->lm-eval==0.4.4->axolotl[deepspeed,flash-attn]) (5.3.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn>=0.14.0->gradio==3.50.2->axolotl[deepspeed,flash-attn]) (0.14.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->optimum==1.16.2->axolotl[deepspeed,flash-attn]) (10.0)\n",
            "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi->gradio==3.50.2->axolotl[deepspeed,flash-attn]) (0.45.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib->gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (2.0.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (2.19.2)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (2.7.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (1.6.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->gradio==3.50.2->axolotl[deepspeed,flash-attn]) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->gradio==3.50.2->axolotl[deepspeed,flash-attn]) (1.0.7)\n",
            "Requirement already satisfied: DataProperty<2,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from pytablewriter->lm-eval==0.4.4->axolotl[deepspeed,flash-attn]) (1.1.0)\n",
            "Requirement already satisfied: mbstrdecoder<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from pytablewriter->lm-eval==0.4.4->axolotl[deepspeed,flash-attn]) (1.1.4)\n",
            "Requirement already satisfied: pathvalidate<4,>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from pytablewriter->lm-eval==0.4.4->axolotl[deepspeed,flash-attn]) (3.2.3)\n",
            "Requirement already satisfied: tabledata<2,>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from pytablewriter->lm-eval==0.4.4->axolotl[deepspeed,flash-attn]) (1.3.4)\n",
            "Requirement already satisfied: tcolorpy<1,>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from pytablewriter->lm-eval==0.4.4->axolotl[deepspeed,flash-attn]) (0.1.7)\n",
            "Requirement already satisfied: typepy<2,>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm-eval==0.4.4->axolotl[deepspeed,flash-attn]) (1.3.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl==0.12.1->axolotl[deepspeed,flash-attn]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl==0.12.1->axolotl[deepspeed,flash-attn]) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->axolotl[deepspeed,flash-attn]) (5.0.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (1.66.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (1.26.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2->axolotl[deepspeed,flash-attn]) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2->axolotl[deepspeed,flash-attn]) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2->axolotl[deepspeed,flash-attn]) (0.22.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl==0.12.1->axolotl[deepspeed,flash-attn]) (0.1.2)\n",
            "Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.11/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm-eval==0.4.4->axolotl[deepspeed,flash-attn]) (5.2.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (3.2.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->gradio==3.50.2->axolotl[deepspeed,flash-attn]) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e 'git+https://github.com/axolotl-ai-cloud/axolotl.git@78b42a3fe13c49e317bc116b9999c30e070322cc#egg=axolotl' # ensures the same version we used in the course"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxtpu_addh-N",
        "outputId": "ec3416a4-cd57-4395-8696-52b3bc284ce7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining axolotl from git+https://github.com/axolotl-ai-cloud/axolotl.git@78b42a3fe13c49e317bc116b9999c30e070322cc#egg=axolotl\n",
            "  Cloning https://github.com/axolotl-ai-cloud/axolotl.git (to revision 78b42a3fe13c49e317bc116b9999c30e070322cc) to ./src/axolotl\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/axolotl-ai-cloud/axolotl.git /content/src/axolotl\n",
            "  Running command git rev-parse -q --verify 'sha^78b42a3fe13c49e317bc116b9999c30e070322cc'\n",
            "  Running command git fetch -q https://github.com/axolotl-ai-cloud/axolotl.git 78b42a3fe13c49e317bc116b9999c30e070322cc\n",
            "  Running command git checkout -q 78b42a3fe13c49e317bc116b9999c30e070322cc\n",
            "  Resolved https://github.com/axolotl-ai-cloud/axolotl.git to commit 78b42a3fe13c49e317bc116b9999c30e070322cc\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers@ git+https://github.com/huggingface/transformers.git@026a173a64372e9602a16523b8fae9de4b0ff428 (from axolotl)\n",
            "  Cloning https://github.com/huggingface/transformers.git (to revision 026a173a64372e9602a16523b8fae9de4b0ff428) to /tmp/pip-install-_5lb2knt/transformers_f85f05ef7dbd4c159a3b0ad268c39d7c\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-install-_5lb2knt/transformers_f85f05ef7dbd4c159a3b0ad268c39d7c\n",
            "  Running command git rev-parse -q --verify 'sha^026a173a64372e9602a16523b8fae9de4b0ff428'\n",
            "  Running command git fetch -q https://github.com/huggingface/transformers.git 026a173a64372e9602a16523b8fae9de4b0ff428\n",
            "  Running command git checkout -q 026a173a64372e9602a16523b8fae9de4b0ff428\n",
            "  Resolved https://github.com/huggingface/transformers.git to commit 026a173a64372e9602a16523b8fae9de4b0ff428\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe (from axolotl)\n",
            "  Cloning https://github.com/lm-sys/FastChat.git (to revision 27a05b04a35510afb1d767ae7e5990cbd278f8fe) to /tmp/pip-install-_5lb2knt/fschat_2c3ff503c1ac4a4a812b33d112eb3188\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/lm-sys/FastChat.git /tmp/pip-install-_5lb2knt/fschat_2c3ff503c1ac4a4a812b33d112eb3188\n",
            "  Running command git rev-parse -q --verify 'sha^27a05b04a35510afb1d767ae7e5990cbd278f8fe'\n",
            "  Running command git fetch -q https://github.com/lm-sys/FastChat.git 27a05b04a35510afb1d767ae7e5990cbd278f8fe\n",
            "  Running command git checkout -q 27a05b04a35510afb1d767ae7e5990cbd278f8fe\n",
            "  Resolved https://github.com/lm-sys/FastChat.git to commit 27a05b04a35510afb1d767ae7e5990cbd278f8fe\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging==23.2 in /usr/local/lib/python3.11/dist-packages (from axolotl) (23.2)\n",
            "Collecting peft==0.11.1 (from axolotl)\n",
            "  Downloading peft-0.11.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting tokenizers==0.19.1 (from axolotl)\n",
            "  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting bitsandbytes==0.43.3 (from axolotl)\n",
            "  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting accelerate==0.32.0 (from axolotl)\n",
            "  Downloading accelerate-0.32.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: pydantic==2.6.3 in /usr/local/lib/python3.11/dist-packages (from axolotl) (2.6.3)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.11/dist-packages (from axolotl) (2.4.0)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.11/dist-packages (from axolotl) (0.7.0)\n",
            "Requirement already satisfied: PyYAML>=6.0 in /usr/local/lib/python3.11/dist-packages (from axolotl) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from axolotl) (2.32.3)\n",
            "Collecting datasets==2.19.1 (from axolotl)\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from axolotl) (0.2.0)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from axolotl) (0.19.6)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from axolotl) (0.8.0)\n",
            "Collecting xformers==0.0.27 (from axolotl)\n",
            "  Downloading xformers-0.0.27-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: optimum==1.16.2 in /usr/local/lib/python3.11/dist-packages (from axolotl) (1.16.2)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (from axolotl) (0.1.9)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from axolotl) (0.4.6)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from axolotl) (0.61.0)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from axolotl) (1.26.4)\n",
            "Requirement already satisfied: evaluate==0.4.1 in /usr/local/lib/python3.11/dist-packages (from axolotl) (0.4.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from axolotl) (1.13.1)\n",
            "Collecting scikit-learn==1.2.2 (from axolotl)\n",
            "  Downloading scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting pynvml (from axolotl)\n",
            "  Downloading pynvml-12.0.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: art in /usr/local/lib/python3.11/dist-packages (from axolotl) (6.4)\n",
            "Requirement already satisfied: gradio==3.50.2 in /usr/local/lib/python3.11/dist-packages (from axolotl) (3.50.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from axolotl) (2.18.0)\n",
            "Requirement already satisfied: python-dotenv==1.0.1 in /usr/local/lib/python3.11/dist-packages (from axolotl) (1.0.1)\n",
            "Collecting autoawq>=0.2.5 (from axolotl)\n",
            "  Downloading autoawq-0.2.8.tar.gz (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: s3fs in /usr/local/lib/python3.11/dist-packages (from axolotl) (2024.9.0)\n",
            "Requirement already satisfied: gcsfs in /usr/local/lib/python3.11/dist-packages (from axolotl) (2024.9.0.post1)\n",
            "Collecting trl==0.9.6 (from axolotl)\n",
            "  Downloading trl-0.9.6-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: zstandard==0.22.0 in /usr/local/lib/python3.11/dist-packages (from axolotl) (0.22.0)\n",
            "Requirement already satisfied: fastcore in /usr/local/lib/python3.11/dist-packages (from axolotl) (1.7.29)\n",
            "Requirement already satisfied: torch==2.5.1+cu124 in /usr/local/lib/python3.11/dist-packages (from axolotl) (2.5.1+cu124)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.32.0->axolotl) (5.9.5)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from accelerate==0.32.0->axolotl) (0.28.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.32.0->axolotl) (0.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets==2.19.1->axolotl) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.19.1->axolotl) (17.0.0)\n",
            "Collecting pyarrow-hotfix (from datasets==2.19.1->axolotl)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.19.1->axolotl) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==2.19.1->axolotl) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets==2.19.1->axolotl) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets==2.19.1->axolotl) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets==2.19.1->axolotl) (0.70.16)\n",
            "Collecting fsspec<=2024.3.1,>=2023.1.0 (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets==2.19.1->axolotl)\n",
            "  Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==2.19.1->axolotl) (3.11.11)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.11/dist-packages (from evaluate==0.4.1->axolotl) (0.18.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2->axolotl) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2->axolotl) (5.5.0)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2->axolotl) (0.115.8)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2->axolotl) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==0.6.1 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2->axolotl) (0.6.1)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2->axolotl) (0.28.1)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2->axolotl) (6.5.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2->axolotl) (3.1.5)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2->axolotl) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2->axolotl) (3.10.0)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2->axolotl) (3.10.15)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2->axolotl) (10.4.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2->axolotl) (0.25.1)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2->axolotl) (0.0.20)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2->axolotl) (2.10.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2->axolotl) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2->axolotl) (0.34.0)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2->axolotl) (11.0.3)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from optimum==1.16.2->axolotl) (15.0.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from optimum==1.16.2->axolotl) (1.13.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic==2.6.3->axolotl) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.11/dist-packages (from pydantic==2.6.3->axolotl) (2.16.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2->axolotl) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2->axolotl) (3.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1+cu124->axolotl) (3.4.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1+cu124->axolotl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1+cu124->axolotl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1+cu124->axolotl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1+cu124->axolotl) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1+cu124->axolotl) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1+cu124->axolotl) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1+cu124->axolotl) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1+cu124->axolotl) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1+cu124->axolotl) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1+cu124->axolotl) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1+cu124->axolotl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1+cu124->axolotl) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1+cu124->axolotl) (3.1.0)\n",
            "Collecting tyro>=0.5.11 (from trl==0.9.6->axolotl)\n",
            "  Downloading tyro-0.9.13-py3-none-any.whl.metadata (9.4 kB)\n",
            "INFO: pip is looking at multiple versions of xformers to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting optimum==1.16.2 (from axolotl)\n",
            "  Using cached optimum-1.16.2-py3-none-any.whl.metadata (17 kB)\n",
            "\u001b[31mERROR: Cannot install axolotl and axolotl==0.4.1 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "The conflict is caused by:\n",
            "    axolotl 0.4.1 depends on torch==2.5.1+cu124\n",
            "    accelerate 0.32.0 depends on torch>=1.10.0\n",
            "    bitsandbytes 0.43.3 depends on torch\n",
            "    optimum 1.16.2 depends on torch>=1.11\n",
            "    peft 0.11.1 depends on torch>=1.13.0\n",
            "    trl 0.9.6 depends on torch>=1.4.0\n",
            "    xformers 0.0.27 depends on torch==2.3.1\n",
            "\n",
            "To fix this you could try to:\n",
            "1. loosen the range of package versions you've specified\n",
            "2. remove package versions to allow pip to attempt to solve the dependency conflict\n",
            "\n",
            "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "train_config = \"\"\"\n",
        "# model params\n",
        "base_model: unsloth/Llama-3.2-1B-Instruct\n",
        "\n",
        "# dataset params\n",
        "datasets:\n",
        "  - path: jaydenccc/AI_Storyteller_Dataset\n",
        "    type:\n",
        "      system_prompt: \"You are an amazing storyteller. From the following synopsis, create an engaging story.\"\n",
        "      field_system: system\n",
        "      field_instruction: synopsis\n",
        "      field_output: short_story\n",
        "      format: \"<|user|>\\n {instruction} </s>\\n<|assistant|>\"\n",
        "      no_input_format: \"<|user|> {instruction} </s>\\n<|assistant|>\"\n",
        "\n",
        "output_dir: ./models/Llama3_Storyteller2\n",
        "\n",
        "\n",
        "# model params\n",
        "sequence_length: 512\n",
        "bf16: auto\n",
        "tf32: false\n",
        "\n",
        "# training params\n",
        "micro_batch_size: 1\n",
        "num_epochs: 1\n",
        "optimizer: adamw_bnb_8bit\n",
        "learning_rate: 0.0001\n",
        "\n",
        "logging_steps: 1\n",
        "\n",
        "\n",
        "# LoRA\n",
        "adapter: lora\n",
        "\n",
        "lora_r: 16\n",
        "lora_alpha: 16\n",
        "lora_dropout: 0.05\n",
        "\n",
        "lora_target_linear: true\n",
        "\n",
        "# Gradient Accumulation\n",
        "gradient_accumulation_steps: 1\n",
        "\n",
        "# Gradient Checkpointing\n",
        "gradient_checkpointing: true\n",
        "\"\"\"\n",
        "\n",
        "# Convert the YAML string to a Python dictionary\n",
        "yaml_dict = yaml.safe_load(train_config)\n",
        "\n",
        "\n",
        "# Write the YAML file\n",
        "with open(\"advanced_train.yml\", 'w') as file:\n",
        "    yaml.dump(yaml_dict, file)\n"
      ],
      "metadata": {
        "id": "JosA-UpgdwzR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNDMbYiZhH2x",
        "outputId": "0b000c7b-d63c-4630-d116-e6e9dcddec2f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: transformers\n",
            "Version: 4.48.2\n",
            "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
            "Home-page: https://github.com/huggingface/transformers\n",
            "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
            "Author-email: transformers@huggingface.co\n",
            "License: Apache 2.0 License\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
            "Required-by: axolotl, lm_eval, optimum, peft, sentence-transformers, trl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show axolotl\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WplmiWtAhKh4",
        "outputId": "272da2ca-8d44-4ee1-eaa9-4e5f5ce08c5c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: axolotl\n",
            "Version: 0.6.0\n",
            "Summary: LLM Trainer\n",
            "Home-page: https://axolotl-ai-cloud.github.io/axolotl/\n",
            "Author: \n",
            "Author-email: \n",
            "License: \n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: accelerate, addict, antlr4-python3-runtime, art, bitsandbytes, colorama, datasets, einops, evaluate, fastcore, fire, gcsfs, gradio, hf-transfer, immutabledict, langdetect, liger-kernel, lm-eval, numba, numpy, nvidia-ml-py, optimum, packaging, peft, pydantic, python-dotenv, PyYAML, requests, s3fs, schedulefree, scikit-learn, scipy, sentencepiece, tensorboard, tokenizers, torch, torchao, transformers, triton, trl, wandb, xformers, zstandard\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.47.1 --force-reinstall\n",
        "# !pip install --upgrade transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0CJmYPmHhNCi",
        "outputId": "745f914c-9654-4925-c135-dd1d93f93aca"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.47.1\n",
            "  Using cached transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n",
            "Collecting filelock (from transformers==4.47.1)\n",
            "  Using cached filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting huggingface-hub<1.0,>=0.24.0 (from transformers==4.47.1)\n",
            "  Using cached huggingface_hub-0.28.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting numpy>=1.17 (from transformers==4.47.1)\n",
            "  Using cached numpy-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Collecting packaging>=20.0 (from transformers==4.47.1)\n",
            "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pyyaml>=5.1 (from transformers==4.47.1)\n",
            "  Using cached PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting regex!=2019.12.17 (from transformers==4.47.1)\n",
            "  Using cached regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "Collecting requests (from transformers==4.47.1)\n",
            "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers==4.47.1)\n",
            "  Using cached tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting safetensors>=0.4.1 (from transformers==4.47.1)\n",
            "  Using cached safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting tqdm>=4.27 (from transformers==4.47.1)\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.24.0->transformers==4.47.1)\n",
            "  Using cached fsspec-2025.2.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub<1.0,>=0.24.0->transformers==4.47.1)\n",
            "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests->transformers==4.47.1)\n",
            "  Using cached charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->transformers==4.47.1)\n",
            "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->transformers==4.47.1)\n",
            "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->transformers==4.47.1)\n",
            "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
            "Using cached transformers-4.47.1-py3-none-any.whl (10.1 MB)\n",
            "Using cached huggingface_hub-0.28.1-py3-none-any.whl (464 kB)\n",
            "Using cached numpy-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
            "Using cached PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n",
            "Using cached regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
            "Using cached safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (461 kB)\n",
            "Using cached tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Using cached filelock-3.17.0-py3-none-any.whl (16 kB)\n",
            "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
            "Using cached charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\n",
            "Using cached fsspec-2025.2.0-py3-none-any.whl (184 kB)\n",
            "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
            "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "Installing collected packages: urllib3, typing-extensions, tqdm, safetensors, regex, pyyaml, packaging, numpy, idna, fsspec, filelock, charset-normalizer, certifi, requests, huggingface-hub, tokenizers, transformers\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.3.0\n",
            "    Uninstalling urllib3-2.3.0:\n",
            "      Successfully uninstalled urllib3-2.3.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: safetensors\n",
            "    Found existing installation: safetensors 0.5.2\n",
            "    Uninstalling safetensors-0.5.2:\n",
            "      Successfully uninstalled safetensors-0.5.2\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2024.11.6\n",
            "    Uninstalling regex-2024.11.6:\n",
            "      Successfully uninstalled regex-2024.11.6\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.2\n",
            "    Uninstalling PyYAML-6.0.2:\n",
            "      Successfully uninstalled PyYAML-6.0.2\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.1.0\n",
            "    Uninstalling numpy-2.1.0:\n",
            "      Successfully uninstalled numpy-2.1.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.2.0\n",
            "    Uninstalling fsspec-2025.2.0:\n",
            "      Successfully uninstalled fsspec-2025.2.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.17.0\n",
            "    Uninstalling filelock-3.17.0:\n",
            "      Successfully uninstalled filelock-3.17.0\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.1\n",
            "    Uninstalling charset-normalizer-3.4.1:\n",
            "      Successfully uninstalled charset-normalizer-3.4.1\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.1.31\n",
            "    Uninstalling certifi-2025.1.31:\n",
            "      Successfully uninstalled certifi-2025.1.31\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.28.1\n",
            "    Uninstalling huggingface-hub-0.28.1:\n",
            "      Successfully uninstalled huggingface-hub-0.28.1\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.0\n",
            "    Uninstalling tokenizers-0.21.0:\n",
            "      Successfully uninstalled tokenizers-0.21.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.47.1\n",
            "    Uninstalling transformers-4.47.1:\n",
            "      Successfully uninstalled transformers-4.47.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gradio 3.50.2 requires numpy~=1.0, but you have numpy 2.2.2 which is incompatible.\n",
            "s3fs 2024.9.0 requires fsspec==2024.9.0.*, but you have fsspec 2025.2.0 which is incompatible.\n",
            "gcsfs 2024.9.0.post1 requires fsspec==2024.9.0, but you have fsspec 2025.2.0 which is incompatible.\n",
            "axolotl 0.6.0 requires numpy<=2.0.1,>=1.24.4, but you have numpy 2.2.2 which is incompatible.\n",
            "axolotl 0.6.0 requires packaging==23.2, but you have packaging 24.2 which is incompatible.\n",
            "datasets 3.1.0 requires fsspec[http]<=2024.9.0,>=2023.1.0, but you have fsspec 2025.2.0 which is incompatible.\n",
            "albumentations 2.0.3 requires pydantic>=2.9.2, but you have pydantic 2.6.3 which is incompatible.\n",
            "langchain 0.3.17 requires numpy<2,>=1.22.4; python_version < \"3.12\", but you have numpy 2.2.2 which is incompatible.\n",
            "langchain 0.3.17 requires pydantic<3.0.0,>=2.7.4, but you have pydantic 2.6.3 which is incompatible.\n",
            "google-genai 0.8.0 requires websockets<15.0dev,>=13.0, but you have websockets 11.0.3 which is incompatible.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.2 which is incompatible.\n",
            "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.2.2 which is incompatible.\n",
            "langsmith 0.3.5 requires zstandard<0.24.0,>=0.23.0, but you have zstandard 0.22.0 which is incompatible.\n",
            "pytensor 2.26.4 requires numpy<2,>=1.17.0, but you have numpy 2.2.2 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.2 which is incompatible.\n",
            "numba 0.61.0 requires numpy<2.2,>=1.24, but you have numpy 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed certifi-2025.1.31 charset-normalizer-3.4.1 filelock-3.17.0 fsspec-2025.2.0 huggingface-hub-0.28.1 idna-3.10 numpy-2.2.2 packaging-24.2 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.3 safetensors-0.5.2 tokenizers-0.21.0 tqdm-4.67.1 transformers-4.47.1 typing-extensions-4.12.2 urllib3-2.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi"
                ]
              },
              "id": "2de4989286154463a0dd1edb36215c61"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==2.1 --force-reinstall\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxbe1uDJhRA2",
        "outputId": "0430cb4d-3497-49d4-c3a5-bafdc645a145"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==2.1\n",
            "  Using cached numpy-2.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Using cached numpy-2.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.2\n",
            "    Uninstalling numpy-2.2.2:\n",
            "      Successfully uninstalled numpy-2.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gradio 3.50.2 requires numpy~=1.0, but you have numpy 2.1.0 which is incompatible.\n",
            "axolotl 0.6.0 requires numpy<=2.0.1,>=1.24.4, but you have numpy 2.1.0 which is incompatible.\n",
            "axolotl 0.6.0 requires packaging==23.2, but you have packaging 24.2 which is incompatible.\n",
            "datasets 3.1.0 requires fsspec[http]<=2024.9.0,>=2023.1.0, but you have fsspec 2025.2.0 which is incompatible.\n",
            "albumentations 2.0.3 requires pydantic>=2.9.2, but you have pydantic 2.6.3 which is incompatible.\n",
            "langchain 0.3.17 requires numpy<2,>=1.22.4; python_version < \"3.12\", but you have numpy 2.1.0 which is incompatible.\n",
            "langchain 0.3.17 requires pydantic<3.0.0,>=2.7.4, but you have pydantic 2.6.3 which is incompatible.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.1.0 which is incompatible.\n",
            "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.1.0 which is incompatible.\n",
            "pytensor 2.26.4 requires numpy<2,>=1.17.0, but you have numpy 2.1.0 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch -m axolotl.cli.train advanced_train.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_VYiiwxe1V_",
        "outputId": "c261a344-eb53-41b8-c597-0132ca203715"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2025-02-09 16:47:40.784223: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1739119660.812439    9825 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1739119660.822585    9825 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-09 16:47:40.856933: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[2025-02-09 16:47:45,821] [INFO] [datasets.<module>:54] [PID:9825] PyTorch version 2.5.1+cu124 available.\n",
            "[2025-02-09 16:47:45,823] [INFO] [datasets.<module>:66] [PID:9825] Polars version 1.9.0 available.\n",
            "[2025-02-09 16:47:45,824] [INFO] [datasets.<module>:77] [PID:9825] Duckdb version 1.1.3 available.\n",
            "[2025-02-09 16:47:45,824] [INFO] [datasets.<module>:112] [PID:9825] TensorFlow version 2.18.0 available.\n",
            "[2025-02-09 16:47:45,825] [INFO] [datasets.<module>:125] [PID:9825] JAX version 0.4.33 available.\n",
            "[2025-02-09 16:47:47,273] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2025-02-09 16:47:47,395] [INFO] [root.spawn:60] [PID:9825] x86_64-linux-gnu-gcc -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -c /tmp/tmpvwndkqbi/test.c -o /tmp/tmpvwndkqbi/test.o\n",
            "[2025-02-09 16:47:47,435] [INFO] [root.spawn:60] [PID:9825] x86_64-linux-gnu-gcc /tmp/tmpvwndkqbi/test.o -laio -o /tmp/tmpvwndkqbi/a.out\n",
            "[2025-02-09 16:47:48,148] [INFO] [root.spawn:60] [PID:9825] x86_64-linux-gnu-gcc -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -c /tmp/tmp7spe_wpr/test.c -o /tmp/tmp7spe_wpr/test.o\n",
            "[2025-02-09 16:47:48,165] [INFO] [root.spawn:60] [PID:9825] x86_64-linux-gnu-gcc /tmp/tmp7spe_wpr/test.o -L/usr/local/cuda -L/usr/local/cuda/lib64 -lcufile -o /tmp/tmp7spe_wpr/a.out\n",
            "[2025-02-09 16:47:48,225] [INFO] [root.spawn:60] [PID:9825] x86_64-linux-gnu-gcc -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -c /tmp/tmpc2b_fua2/test.c -o /tmp/tmpc2b_fua2/test.o\n",
            "[2025-02-09 16:47:48,241] [INFO] [root.spawn:60] [PID:9825] x86_64-linux-gnu-gcc /tmp/tmpc2b_fua2/test.o -laio -o /tmp/tmpc2b_fua2/a.out\n",
            "/usr/local/lib/python3.11/dist-packages/axolotl/monkeypatch/relora.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
            "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
            "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_kwargs\" has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n",
            "\u001b[33m[2025-02-09 16:47:51,593] [WARNING] [axolotl.utils.config.models.input.hint_lora_8bit:1251] [PID:9825] [RANK:0] We recommend setting `load_in_8bit: true` for LORA finetuning\u001b[39m\n",
            "[2025-02-09 16:47:51,639] [DEBUG] [axolotl.normalize_config:87] [PID:9825] [RANK:0] bf16 support detected, enabling for this configuration.\u001b[39m\n",
            "config.json: 100% 944/944 [00:00<00:00, 4.27MB/s]\n",
            "[2025-02-09 16:47:51,859] [INFO] [axolotl.normalize_config:211] [PID:9825] [RANK:0] cuda memory usage baseline: 0.000GB (+0.002GB cache, +0.359GB misc)\u001b[39m\n",
            "\n",
            "     #@@ #@@      @@# @@#\n",
            "    @@  @@          @@  @@           =@@#                               @@                 #@    =@@#.\n",
            "    @@    #@@@@@@@@@    @@           #@#@=                              @@                 #@     .=@@\n",
            "      #@@@@@@@@@@@@@@@@@            =@# @#     ##=     ##    =####=+    @@      =#####+  =#@@###.   @@\n",
            "    @@@@@@@@@@/  +@@/  +@@          #@  =@=     #@=   @@   =@#+  +#@#   @@    =@#+  +#@#   #@.      @@\n",
            "    @@@@@@@@@@  ##@@  ##@@         =@#   @#      =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
            "     @@@@@@@@@@@@@@@@@@@@          #@=+++#@=      =@@#     @@      @@   @@    @@      #@   #@       @@\n",
            "                                  =@#=====@@     =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
            "    @@@@@@@@@@@@@@@@  @@@@        #@      #@=   #@=  +@@   #@#    =@#   @@.   =@#    =@#   #@.      @@\n",
            "                                 =@#       @#  #@=     #@   =#@@@@#=    +#@@=  +#@@@@#=    .##@@+   @@\n",
            "    @@@@  @@@@@@@@@@@@@@@@\n",
            "\n",
            "\u001b[33m[2025-02-09 16:47:51,892] [WARNING] [axolotl.scripts.check_user_token:565] [PID:9825] [RANK:0] Error verifying HuggingFace token. Remember to log in using `huggingface-cli login` and get your access token from https://huggingface.co/settings/tokens if you want to use gated models or datasets.\u001b[39m\n",
            "tokenizer_config.json: 100% 54.7k/54.7k [00:00<00:00, 9.46MB/s]\n",
            "tokenizer.json: 100% 17.2M/17.2M [00:00<00:00, 40.6MB/s]\n",
            "special_tokens_map.json: 100% 454/454 [00:00<00:00, 2.92MB/s]\n",
            "[2025-02-09 16:47:53,999] [DEBUG] [axolotl.load_tokenizer:296] [PID:9825] [RANK:0] EOS: 128009 / <|eot_id|>\u001b[39m\n",
            "[2025-02-09 16:47:53,999] [DEBUG] [axolotl.load_tokenizer:297] [PID:9825] [RANK:0] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
            "[2025-02-09 16:47:53,999] [DEBUG] [axolotl.load_tokenizer:298] [PID:9825] [RANK:0] PAD: 128004 / <|finetune_right_pad_id|>\u001b[39m\n",
            "[2025-02-09 16:47:53,999] [DEBUG] [axolotl.load_tokenizer:299] [PID:9825] [RANK:0] UNK: None / None\u001b[39m\n",
            "[2025-02-09 16:47:53,999] [INFO] [axolotl.load_tokenizer:313] [PID:9825] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
            "[2025-02-09 16:47:53,999] [INFO] [axolotl.load_tokenized_prepared_datasets:216] [PID:9825] [RANK:0] Unable to find prepared dataset in last_run_prepared/bb7c6132f9ba4de7fc45c66e7cdda198\u001b[39m\n",
            "[2025-02-09 16:47:53,999] [INFO] [axolotl.load_tokenized_prepared_datasets:217] [PID:9825] [RANK:0] Loading raw datasets...\u001b[39m\n",
            "\u001b[33m[2025-02-09 16:47:53,999] [WARNING] [axolotl.load_tokenized_prepared_datasets:219] [PID:9825] [RANK:0] Processing datasets during training can lead to VRAM instability. Please pre-process your dataset.\u001b[39m\n",
            "[2025-02-09 16:47:53,999] [INFO] [axolotl.load_tokenized_prepared_datasets:226] [PID:9825] [RANK:0] No seed provided, using default seed of 42\u001b[39m\n",
            "[2025-02-09 16:47:56,562] [INFO] [axolotl.get_dataset_wrapper:613] [PID:9825] [RANK:0] Loading dataset with base_type: None and prompt_style: None\u001b[39m\n",
            "Tokenizing Prompts (num_proc=2): 100% 100/100 [00:01<00:00, 51.95 examples/s]\n",
            "[2025-02-09 16:47:58,779] [INFO] [axolotl.load_tokenized_prepared_datasets:486] [PID:9825] [RANK:0] Saving merged prepared dataset to disk... last_run_prepared/bb7c6132f9ba4de7fc45c66e7cdda198\u001b[39m\n",
            "Saving the dataset (1/1 shards): 100% 100/100 [00:00<00:00, 21163.05 examples/s]\n",
            "[2025-02-09 16:47:58,790] [DEBUG] [axolotl.calculate_total_num_steps:342] [PID:9825] [RANK:0] total_num_tokens: 44_422\u001b[39m\n",
            "[2025-02-09 16:47:58,791] [DEBUG] [axolotl.calculate_total_num_steps:360] [PID:9825] [RANK:0] `total_supervised_tokens: 39_997`\u001b[39m\n",
            "[2025-02-09 16:47:58,792] [DEBUG] [axolotl.calculate_total_num_steps:438] [PID:9825] [RANK:0] total_num_steps: 100\u001b[39m\n",
            "[2025-02-09 16:47:58,792] [DEBUG] [axolotl.train.train:66] [PID:9825] [RANK:0] loading tokenizer... unsloth/Llama-3.2-1B-Instruct\u001b[39m\n",
            "[2025-02-09 16:47:59,681] [DEBUG] [axolotl.load_tokenizer:296] [PID:9825] [RANK:0] EOS: 128009 / <|eot_id|>\u001b[39m\n",
            "[2025-02-09 16:47:59,681] [DEBUG] [axolotl.load_tokenizer:297] [PID:9825] [RANK:0] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
            "[2025-02-09 16:47:59,681] [DEBUG] [axolotl.load_tokenizer:298] [PID:9825] [RANK:0] PAD: 128004 / <|finetune_right_pad_id|>\u001b[39m\n",
            "[2025-02-09 16:47:59,681] [DEBUG] [axolotl.load_tokenizer:299] [PID:9825] [RANK:0] UNK: None / None\u001b[39m\n",
            "[2025-02-09 16:47:59,681] [INFO] [axolotl.load_tokenizer:313] [PID:9825] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
            "[2025-02-09 16:47:59,682] [DEBUG] [axolotl.train.train:98] [PID:9825] [RANK:0] loading model and peft_config...\u001b[39m\n",
            "[2025-02-09 16:47:59,785] [INFO] [axolotl.monkeypatch.trainer_grad_accum.patch_forward_for_ga:203] [PID:9825] [RANK:0] patching forward\u001b[39m\n",
            "model.safetensors: 100% 2.47G/2.47G [00:58<00:00, 42.0MB/s]\n",
            "generation_config.json: 100% 234/234 [00:00<00:00, 2.12MB/s]\n",
            "[2025-02-09 16:48:59,842] [INFO] [axolotl.load_model:1121] [PID:9825] [RANK:0] Converting modules to torch.bfloat16\u001b[39m\n",
            "[2025-02-09 16:49:00,313] [INFO] [axolotl.load_lora:1310] [PID:9825] [RANK:0] found linear modules: ['down_proj', 'gate_proj', 'k_proj', 'o_proj', 'q_proj', 'up_proj', 'v_proj']\u001b[39m\n",
            "trainable params: 11,272,192 || all params: 1,247,086,592 || trainable%: 0.9039\n",
            "[2025-02-09 16:49:01,028] [INFO] [axolotl.load_model:1182] [PID:9825] [RANK:0] cuda memory usage after adapters: 0.000GB ()\u001b[39m\n",
            "/usr/local/lib/python3.11/dist-packages/axolotl/core/trainer_builder.py:444: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `AxolotlTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*_args, **kwargs)\n",
            "[2025-02-09 16:49:03,400] [INFO] [axolotl.train.train:141] [PID:9825] [RANK:0] Pre-saving adapter config to ./models/Llama3_Storyteller2\u001b[39m\n",
            "[2025-02-09 16:49:03,717] [INFO] [axolotl.train.train:178] [PID:9825] [RANK:0] Starting trainer...\u001b[39m\n",
            "  0% 0/100 [00:00<?, ?it/s]You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "{'loss': 1.3681, 'grad_norm': 0.8696810007095337, 'learning_rate': 3.3333333333333335e-05, 'epoch': 0.01}\n",
            "  1% 1/100 [00:03<05:15,  3.19s/it][2025-02-09 16:49:10,544] [INFO] [axolotl.callbacks.on_step_end:130] [PID:9825] [RANK:0] cuda memory usage while training: 2.382GB (+1.079GB cache, +0.392GB misc)\u001b[39m\n",
            "{'loss': 1.7895, 'grad_norm': 0.9256244897842407, 'learning_rate': 6.666666666666667e-05, 'epoch': 0.02}\n",
            "{'loss': 1.498, 'grad_norm': 0.9578790664672852, 'learning_rate': 0.0001, 'epoch': 0.03}\n",
            "{'loss': 1.436, 'grad_norm': 0.7522019147872925, 'learning_rate': 9.997377845227576e-05, 'epoch': 0.04}\n",
            "{'loss': 1.3033, 'grad_norm': 0.9312046766281128, 'learning_rate': 9.989514131188559e-05, 'epoch': 0.05}\n",
            "{'loss': 1.5301, 'grad_norm': 0.7607853412628174, 'learning_rate': 9.97641710583307e-05, 'epoch': 0.06}\n",
            "{'loss': 1.559, 'grad_norm': 0.8632515072822571, 'learning_rate': 9.958100506132127e-05, 'epoch': 0.07}\n",
            "{'loss': 1.5407, 'grad_norm': 1.1328222751617432, 'learning_rate': 9.934583543669453e-05, 'epoch': 0.08}\n",
            "{'loss': 1.5291, 'grad_norm': 0.8556376695632935, 'learning_rate': 9.905890884491195e-05, 'epoch': 0.09}\n",
            "{'loss': 1.3571, 'grad_norm': 0.7051292061805725, 'learning_rate': 9.872052623234632e-05, 'epoch': 0.1}\n",
            "{'loss': 1.9099, 'grad_norm': 0.7031110525131226, 'learning_rate': 9.833104251563056e-05, 'epoch': 0.11}\n",
            "{'loss': 1.615, 'grad_norm': 0.769032895565033, 'learning_rate': 9.789086620939936e-05, 'epoch': 0.12}\n",
            "{'loss': 1.514, 'grad_norm': 0.8625836372375488, 'learning_rate': 9.740045899781352e-05, 'epoch': 0.13}\n",
            "{'loss': 1.9784, 'grad_norm': 0.729134738445282, 'learning_rate': 9.686033525031719e-05, 'epoch': 0.14}\n",
            "{'loss': 1.4641, 'grad_norm': 0.7320364117622375, 'learning_rate': 9.627106148213522e-05, 'epoch': 0.15}\n",
            "{'loss': 1.5805, 'grad_norm': 0.6880910396575928, 'learning_rate': 9.563325576007701e-05, 'epoch': 0.16}\n",
            "{'loss': 1.4588, 'grad_norm': 0.7269424200057983, 'learning_rate': 9.494758705426978e-05, 'epoch': 0.17}\n",
            "{'loss': 1.4647, 'grad_norm': 0.8596835136413574, 'learning_rate': 9.421477453650118e-05, 'epoch': 0.18}\n",
            "{'loss': 1.5777, 'grad_norm': 0.8813790678977966, 'learning_rate': 9.343558682590756e-05, 'epoch': 0.19}\n",
            "{'loss': 1.6641, 'grad_norm': 0.7645204067230225, 'learning_rate': 9.261084118279847e-05, 'epoch': 0.2}\n",
            "{'loss': 1.2033, 'grad_norm': 0.7208687663078308, 'learning_rate': 9.174140265146356e-05, 'epoch': 0.21}\n",
            "{'loss': 1.1978, 'grad_norm': 0.7700566053390503, 'learning_rate': 9.082818315286055e-05, 'epoch': 0.22}\n",
            "{'loss': 1.561, 'grad_norm': 0.7787590622901917, 'learning_rate': 8.987214052813604e-05, 'epoch': 0.23}\n",
            "{'loss': 1.4958, 'grad_norm': 0.7656897902488708, 'learning_rate': 8.887427753398248e-05, 'epoch': 0.24}\n",
            "{'loss': 1.8023, 'grad_norm': 0.7975435853004456, 'learning_rate': 8.783564079088477e-05, 'epoch': 0.25}\n",
            "{'loss': 1.5154, 'grad_norm': 0.831336498260498, 'learning_rate': 8.675731968536002e-05, 'epoch': 0.26}\n",
            "{'loss': 1.703, 'grad_norm': 0.8059508204460144, 'learning_rate': 8.564044522734147e-05, 'epoch': 0.27}\n",
            "{'loss': 1.6234, 'grad_norm': 0.805690348148346, 'learning_rate': 8.448618886390522e-05, 'epoch': 0.28}\n",
            "{'loss': 1.5398, 'grad_norm': 0.8118674159049988, 'learning_rate': 8.329576125058406e-05, 'epoch': 0.29}\n",
            "{'loss': 1.4718, 'grad_norm': 0.7841086983680725, 'learning_rate': 8.2070410981557e-05, 'epoch': 0.3}\n",
            "{'loss': 1.2977, 'grad_norm': 0.7193736433982849, 'learning_rate': 8.081142328004637e-05, 'epoch': 0.31}\n",
            "{'loss': 1.7657, 'grad_norm': 0.6496762633323669, 'learning_rate': 7.952011865029614e-05, 'epoch': 0.32}\n",
            "{'loss': 1.3379, 'grad_norm': 0.6855036020278931, 'learning_rate': 7.819785149254532e-05, 'epoch': 0.33}\n",
            "{'loss': 1.5852, 'grad_norm': 0.7911619544029236, 'learning_rate': 7.68460086824492e-05, 'epoch': 0.34}\n",
            "{'loss': 1.5134, 'grad_norm': 0.6908450126647949, 'learning_rate': 7.546600811643816e-05, 'epoch': 0.35}\n",
            "{'loss': 1.5462, 'grad_norm': 0.665010392665863, 'learning_rate': 7.405929722454026e-05, 'epoch': 0.36}\n",
            "{'loss': 1.2007, 'grad_norm': 0.9671686887741089, 'learning_rate': 7.262735145222696e-05, 'epoch': 0.37}\n",
            "{'loss': 1.7092, 'grad_norm': 0.779714822769165, 'learning_rate': 7.117167271287453e-05, 'epoch': 0.38}\n",
            "{'loss': 1.6297, 'grad_norm': 0.7490861415863037, 'learning_rate': 6.969378781246436e-05, 'epoch': 0.39}\n",
            "{'loss': 2.2468, 'grad_norm': 0.9601032137870789, 'learning_rate': 6.819524684817438e-05, 'epoch': 0.4}\n",
            "{'loss': 1.2955, 'grad_norm': 0.775719165802002, 'learning_rate': 6.667762158254104e-05, 'epoch': 0.41}\n",
            "{'loss': 1.511, 'grad_norm': 0.7664428353309631, 'learning_rate': 6.514250379489753e-05, 'epoch': 0.42}\n",
            "{'loss': 1.5284, 'grad_norm': 0.6710423827171326, 'learning_rate': 6.359150361181715e-05, 'epoch': 0.43}\n",
            "{'loss': 1.5835, 'grad_norm': 0.820361316204071, 'learning_rate': 6.202624781831268e-05, 'epoch': 0.44}\n",
            "{'loss': 1.4242, 'grad_norm': 0.6716736555099487, 'learning_rate': 6.044837815156377e-05, 'epoch': 0.45}\n",
            "{'loss': 1.287, 'grad_norm': 0.8982223272323608, 'learning_rate': 5.885954957896115e-05, 'epoch': 0.46}\n",
            "{'loss': 1.516, 'grad_norm': 0.7003155946731567, 'learning_rate': 5.726142856227452e-05, 'epoch': 0.47}\n",
            "{'loss': 1.1583, 'grad_norm': 0.8198160529136658, 'learning_rate': 5.565569130976422e-05, 'epoch': 0.48}\n",
            "{'loss': 1.9342, 'grad_norm': 0.7243547439575195, 'learning_rate': 5.4044022018070214e-05, 'epoch': 0.49}\n",
            "{'loss': 1.5242, 'grad_norm': 0.7244752645492554, 'learning_rate': 5.242811110572242e-05, 'epoch': 0.5}\n",
            "{'loss': 1.7948, 'grad_norm': 0.6701255440711975, 'learning_rate': 5.080965344012508e-05, 'epoch': 0.51}\n",
            "{'loss': 1.8732, 'grad_norm': 0.7201045751571655, 'learning_rate': 4.919034655987493e-05, 'epoch': 0.52}\n",
            "{'loss': 1.8333, 'grad_norm': 0.6369521021842957, 'learning_rate': 4.7571888894277604e-05, 'epoch': 0.53}\n",
            "{'loss': 1.2198, 'grad_norm': 0.9388962984085083, 'learning_rate': 4.59559779819298e-05, 'epoch': 0.54}\n",
            "{'loss': 1.5116, 'grad_norm': 0.6376833915710449, 'learning_rate': 4.434430869023579e-05, 'epoch': 0.55}\n",
            "{'loss': 1.3625, 'grad_norm': 0.7836350202560425, 'learning_rate': 4.27385714377255e-05, 'epoch': 0.56}\n",
            "{'loss': 1.409, 'grad_norm': 0.9379211664199829, 'learning_rate': 4.114045042103887e-05, 'epoch': 0.57}\n",
            "{'loss': 1.6174, 'grad_norm': 0.7212952971458435, 'learning_rate': 3.955162184843625e-05, 'epoch': 0.58}\n",
            "{'loss': 1.5482, 'grad_norm': 0.6844720244407654, 'learning_rate': 3.7973752181687335e-05, 'epoch': 0.59}\n",
            "{'loss': 1.4937, 'grad_norm': 0.8410263061523438, 'learning_rate': 3.640849638818286e-05, 'epoch': 0.6}\n",
            "{'loss': 1.4019, 'grad_norm': 0.6265611052513123, 'learning_rate': 3.4857496205102474e-05, 'epoch': 0.61}\n",
            "{'loss': 2.4807, 'grad_norm': 0.8818838596343994, 'learning_rate': 3.332237841745898e-05, 'epoch': 0.62}\n",
            "{'loss': 1.7009, 'grad_norm': 0.8169075846672058, 'learning_rate': 3.180475315182563e-05, 'epoch': 0.63}\n",
            "{'loss': 1.5059, 'grad_norm': 0.7005200982093811, 'learning_rate': 3.0306212187535653e-05, 'epoch': 0.64}\n",
            "{'loss': 1.346, 'grad_norm': 0.8505665063858032, 'learning_rate': 2.882832728712551e-05, 'epoch': 0.65}\n",
            "{'loss': 1.5973, 'grad_norm': 0.7439018487930298, 'learning_rate': 2.737264854777306e-05, 'epoch': 0.66}\n",
            "{'loss': 1.3818, 'grad_norm': 0.7181683778762817, 'learning_rate': 2.5940702775459747e-05, 'epoch': 0.67}\n",
            "{'loss': 1.2312, 'grad_norm': 0.745187520980835, 'learning_rate': 2.4533991883561868e-05, 'epoch': 0.68}\n",
            "{'loss': 1.736, 'grad_norm': 0.7637137770652771, 'learning_rate': 2.315399131755081e-05, 'epoch': 0.69}\n",
            "{'loss': 1.266, 'grad_norm': 0.7641171216964722, 'learning_rate': 2.180214850745467e-05, 'epoch': 0.7}\n",
            "{'loss': 1.3958, 'grad_norm': 0.7631432414054871, 'learning_rate': 2.0479881349703883e-05, 'epoch': 0.71}\n",
            "{'loss': 1.689, 'grad_norm': 0.9434671401977539, 'learning_rate': 1.9188576719953633e-05, 'epoch': 0.72}\n",
            "{'loss': 1.3721, 'grad_norm': 0.6523268222808838, 'learning_rate': 1.7929589018443016e-05, 'epoch': 0.73}\n",
            "{'loss': 1.3217, 'grad_norm': 0.7750512361526489, 'learning_rate': 1.6704238749415957e-05, 'epoch': 0.74}\n",
            "{'loss': 1.3613, 'grad_norm': 0.8305836915969849, 'learning_rate': 1.5513811136094787e-05, 'epoch': 0.75}\n",
            "{'loss': 1.325, 'grad_norm': 0.7819101810455322, 'learning_rate': 1.4359554772658552e-05, 'epoch': 0.76}\n",
            "{'loss': 1.4032, 'grad_norm': 0.9528524875640869, 'learning_rate': 1.3242680314639993e-05, 'epoch': 0.77}\n",
            "{'loss': 1.7997, 'grad_norm': 0.7727429270744324, 'learning_rate': 1.2164359209115234e-05, 'epoch': 0.78}\n",
            "{'loss': 1.9096, 'grad_norm': 0.6377264857292175, 'learning_rate': 1.1125722466017547e-05, 'epoch': 0.79}\n",
            "{'loss': 1.586, 'grad_norm': 0.6754427552223206, 'learning_rate': 1.012785947186397e-05, 'epoch': 0.8}\n",
            "{'loss': 1.8129, 'grad_norm': 0.8268267512321472, 'learning_rate': 9.171816847139448e-06, 'epoch': 0.81}\n",
            "{'loss': 1.5978, 'grad_norm': 0.7047131657600403, 'learning_rate': 8.25859734853645e-06, 'epoch': 0.82}\n",
            "{'loss': 1.3963, 'grad_norm': 0.7154728174209595, 'learning_rate': 7.389158817201542e-06, 'epoch': 0.83}\n",
            "{'loss': 1.4997, 'grad_norm': 0.9718350768089294, 'learning_rate': 6.564413174092443e-06, 'epoch': 0.84}\n",
            "{'loss': 1.0776, 'grad_norm': 0.7052496075630188, 'learning_rate': 5.785225463498828e-06, 'epoch': 0.85}\n",
            "{'loss': 1.3634, 'grad_norm': 0.7679589986801147, 'learning_rate': 5.05241294573024e-06, 'epoch': 0.86}\n",
            "{'loss': 1.3569, 'grad_norm': 0.7824926376342773, 'learning_rate': 4.366744239922998e-06, 'epoch': 0.87}\n",
            "{'loss': 1.6707, 'grad_norm': 0.6706085205078125, 'learning_rate': 3.728938517864794e-06, 'epoch': 0.88}\n",
            "{'loss': 1.578, 'grad_norm': 0.8294434547424316, 'learning_rate': 3.1396647496828247e-06, 'epoch': 0.89}\n",
            "{'loss': 1.6073, 'grad_norm': 0.733229398727417, 'learning_rate': 2.5995410021864787e-06, 'epoch': 0.9}\n",
            "{'loss': 1.6725, 'grad_norm': 0.7741566300392151, 'learning_rate': 2.1091337906006482e-06, 'epoch': 0.91}\n",
            "{'loss': 1.3268, 'grad_norm': 0.712853193283081, 'learning_rate': 1.6689574843694433e-06, 'epoch': 0.92}\n",
            "{'loss': 1.7851, 'grad_norm': 0.8480692505836487, 'learning_rate': 1.2794737676536994e-06, 'epoch': 0.93}\n",
            "{'loss': 1.4481, 'grad_norm': 0.7128031849861145, 'learning_rate': 9.410911550880475e-07, 'epoch': 0.94}\n",
            "{'loss': 1.8419, 'grad_norm': 0.6992425918579102, 'learning_rate': 6.54164563305465e-07, 'epoch': 0.95}\n",
            "{'loss': 1.6333, 'grad_norm': 0.6573668718338013, 'learning_rate': 4.189949386787462e-07, 'epoch': 0.96}\n",
            "{'loss': 1.5864, 'grad_norm': 0.7681707143783569, 'learning_rate': 2.3582894166930268e-07, 'epoch': 0.97}\n",
            "{'loss': 1.3988, 'grad_norm': 0.6849260330200195, 'learning_rate': 1.0485868811441757e-07, 'epoch': 0.98}\n",
            "{'loss': 1.3809, 'grad_norm': 0.8694233298301697, 'learning_rate': 2.6221547724253337e-08, 'epoch': 0.99}\n",
            "{'loss': 1.2906, 'grad_norm': 0.7484822273254395, 'learning_rate': 0.0, 'epoch': 1.0}\n",
            "{'train_runtime': 176.2526, 'train_samples_per_second': 0.567, 'train_steps_per_second': 0.567, 'train_loss': 1.5364617609977722, 'epoch': 1.0}\n",
            "100% 100/100 [02:56<00:00,  1.76s/it]\n",
            "[2025-02-09 16:52:01,919] [INFO] [axolotl.train.train:195] [PID:9825] [RANK:0] Training Completed!!! Saving pre-trained model to ./models/Llama3_Storyteller2\u001b[39m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: Merge the trained adapter\n",
        "!accelerate launch -m axolotl.cli.merge_lora advanced_train.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jD_oEzlxe12U",
        "outputId": "6d187876-9300-4f51-b49f-0c336ac95806"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2025-02-09 16:52:41.294660: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1739119961.328811   11156 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1739119961.338883   11156 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-09 16:52:41.372016: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[2025-02-09 16:52:45,323] [INFO] [datasets.<module>:54] [PID:11156] PyTorch version 2.5.1+cu124 available.\n",
            "[2025-02-09 16:52:45,324] [INFO] [datasets.<module>:66] [PID:11156] Polars version 1.9.0 available.\n",
            "[2025-02-09 16:52:45,324] [INFO] [datasets.<module>:77] [PID:11156] Duckdb version 1.1.3 available.\n",
            "[2025-02-09 16:52:45,325] [INFO] [datasets.<module>:112] [PID:11156] TensorFlow version 2.18.0 available.\n",
            "[2025-02-09 16:52:45,326] [INFO] [datasets.<module>:125] [PID:11156] JAX version 0.4.33 available.\n",
            "[2025-02-09 16:52:46,348] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2025-02-09 16:52:46,427] [INFO] [root.spawn:60] [PID:11156] x86_64-linux-gnu-gcc -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -c /tmp/tmppef2c0tl/test.c -o /tmp/tmppef2c0tl/test.o\n",
            "[2025-02-09 16:52:46,446] [INFO] [root.spawn:60] [PID:11156] x86_64-linux-gnu-gcc /tmp/tmppef2c0tl/test.o -laio -o /tmp/tmppef2c0tl/a.out\n",
            "[2025-02-09 16:52:47,150] [INFO] [root.spawn:60] [PID:11156] x86_64-linux-gnu-gcc -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -c /tmp/tmp47i3qhsm/test.c -o /tmp/tmp47i3qhsm/test.o\n",
            "[2025-02-09 16:52:47,168] [INFO] [root.spawn:60] [PID:11156] x86_64-linux-gnu-gcc /tmp/tmp47i3qhsm/test.o -L/usr/local/cuda -L/usr/local/cuda/lib64 -lcufile -o /tmp/tmp47i3qhsm/a.out\n",
            "[2025-02-09 16:52:47,215] [INFO] [root.spawn:60] [PID:11156] x86_64-linux-gnu-gcc -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -c /tmp/tmpbif65yvp/test.c -o /tmp/tmpbif65yvp/test.o\n",
            "[2025-02-09 16:52:47,232] [INFO] [root.spawn:60] [PID:11156] x86_64-linux-gnu-gcc /tmp/tmpbif65yvp/test.o -laio -o /tmp/tmpbif65yvp/a.out\n",
            "/usr/local/lib/python3.11/dist-packages/axolotl/monkeypatch/relora.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
            "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
            "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_kwargs\" has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n",
            "\n",
            "     #@@ #@@      @@# @@#\n",
            "    @@  @@          @@  @@           =@@#                               @@                 #@    =@@#.\n",
            "    @@    #@@@@@@@@@    @@           #@#@=                              @@                 #@     .=@@\n",
            "      #@@@@@@@@@@@@@@@@@            =@# @#     ##=     ##    =####=+    @@      =#####+  =#@@###.   @@\n",
            "    @@@@@@@@@@/  +@@/  +@@          #@  =@=     #@=   @@   =@#+  +#@#   @@    =@#+  +#@#   #@.      @@\n",
            "    @@@@@@@@@@  ##@@  ##@@         =@#   @#      =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
            "     @@@@@@@@@@@@@@@@@@@@          #@=+++#@=      =@@#     @@      @@   @@    @@      #@   #@       @@\n",
            "                                  =@#=====@@     =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
            "    @@@@@@@@@@@@@@@@  @@@@        #@      #@=   #@=  +@@   #@#    =@#   @@.   =@#    =@#   #@.      @@\n",
            "                                 =@#       @#  #@=     #@   =#@@@@#=    +#@@=  +#@@@@#=    .##@@+   @@\n",
            "    @@@@  @@@@@@@@@@@@@@@@\n",
            "\n",
            "\u001b[33m[2025-02-09 16:52:49,527] [WARNING] [axolotl.utils.config.models.input.hint_lora_8bit:1251] [PID:11156] [RANK:0] We recommend setting `load_in_8bit: true` for LORA finetuning\u001b[39m\n",
            "[2025-02-09 16:52:49,563] [DEBUG] [axolotl.normalize_config:87] [PID:11156] [RANK:0] bf16 support detected, enabling for this configuration.\u001b[39m\n",
            "[2025-02-09 16:52:49,684] [INFO] [axolotl.normalize_config:211] [PID:11156] [RANK:0] cuda memory usage baseline: 0.000GB (+0.002GB cache, +0.359GB misc)\u001b[39m\n",
            "[2025-02-09 16:52:49,684] [INFO] [axolotl.common.cli.load_model_and_tokenizer:51] [PID:11156] [RANK:0] loading tokenizer... unsloth/Llama-3.2-1B-Instruct\u001b[39m\n",
            "[2025-02-09 16:52:50,530] [DEBUG] [axolotl.load_tokenizer:296] [PID:11156] [RANK:0] EOS: 128009 / <|eot_id|>\u001b[39m\n",
            "[2025-02-09 16:52:50,530] [DEBUG] [axolotl.load_tokenizer:297] [PID:11156] [RANK:0] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
            "[2025-02-09 16:52:50,530] [DEBUG] [axolotl.load_tokenizer:298] [PID:11156] [RANK:0] PAD: 128004 / <|finetune_right_pad_id|>\u001b[39m\n",
            "[2025-02-09 16:52:50,530] [DEBUG] [axolotl.load_tokenizer:299] [PID:11156] [RANK:0] UNK: None / None\u001b[39m\n",
            "[2025-02-09 16:52:50,530] [INFO] [axolotl.load_tokenizer:313] [PID:11156] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
            "[2025-02-09 16:52:50,530] [INFO] [axolotl.common.cli.load_model_and_tokenizer:53] [PID:11156] [RANK:0] loading model and (optionally) peft_config...\u001b[39m\n",
            "[2025-02-09 16:52:50,636] [INFO] [axolotl.monkeypatch.trainer_grad_accum.patch_forward_for_ga:203] [PID:11156] [RANK:0] patching forward\u001b[39m\n",
            "[2025-02-09 16:52:51,434] [INFO] [axolotl.load_model:1121] [PID:11156] [RANK:0] Converting modules to torch.bfloat16\u001b[39m\n",
            "[2025-02-09 16:52:51,900] [INFO] [axolotl.load_lora:1310] [PID:11156] [RANK:0] found linear modules: ['down_proj', 'gate_proj', 'k_proj', 'o_proj', 'q_proj', 'up_proj', 'v_proj']\u001b[39m\n",
            "[2025-02-09 16:52:51,900] [DEBUG] [axolotl.load_lora:1358] [PID:11156] [RANK:0] Loading pretrained PEFT - LoRA\u001b[39m\n",
            "trainable params: 11,272,192 || all params: 1,247,086,592 || trainable%: 0.9039\n",
            "[2025-02-09 16:52:52,422] [INFO] [axolotl.load_model:1182] [PID:11156] [RANK:0] cuda memory usage after adapters: 0.000GB ()\u001b[39m\n",
            "[2025-02-09 16:52:53,931] [INFO] [axolotl.scripts.do_merge_lora:171] [PID:11156] [RANK:0] running merge of LoRA with base model\u001b[39m\n",
            "Unloading and merging model: 100% 343/343 [00:13<00:00, 25.67it/s]\n",
            "[2025-02-09 16:53:07,300] [INFO] [axolotl.scripts.do_merge_lora:180] [PID:11156] [RANK:0] saving merged model to: models/Llama3_Storyteller2/merged\u001b[39m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "twxYFJ6UgTUG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "bh6vwOsdovgv"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\"text-generation\", model=\"/content/models/Llama3_Storyteller2/merged\", torch_dtype=torch.bfloat16, device_map=\"auto\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSty7FzXoX4S",
        "outputId": "25472cb7-b4db-46f4-8053-a71864a19933"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\":\"system\", \"content\": \"You are an amazing storyteller. From the following synopsis, create an engaging story.\"},\n",
        "    {\"role\": \"user\", \"content\": \"A woman discovers a hidden talent for cooking and starts her own successful restaurant.\"},\n",
        "]\n"
      ],
      "metadata": {
        "id": "XVvhg_WBotI7"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)"
      ],
      "metadata": {
        "id": "5dunSxKopCmn"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = pipe(prompt, max_new_tokens=128)\n",
        "\n",
        "print(outputs[0][\"generated_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kHuEFd-pGWX",
        "outputId": "065c84cf-2d82-4e89-8f33-a8749c90d007"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 09 Feb 2025\n",
            "\n",
            "You are an amazing storyteller. From the following synopsis, create an engaging story.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "A woman discovers a hidden talent for cooking and starts her own successful restaurant.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "As a child, Emma had always been fascinated by the way her mother could transform simple ingredients into culinary masterpieces. She would watch in awe as she sautéed vegetables, roasted meats, and baked bread, the aromas wafting from the kitchen like a warm hug. But it wasn't until her mother passed away that Emma realized her true passion lay in cooking.\n",
            "\n",
            "One day, while rummaging through her mother's old recipe books, Emma stumbled upon a recipe for a traditional Italian dish she had never tried before: homemade ravioli. Intrigued, she decided to give it a go, and to her surprise\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hg_pipe = pipeline(\"text-generation\", model=\"unsloth/Llama-3.2-1B-Instruct\", torch_dtype=torch.bfloat16, device_map=\"auto\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kwERzFupKQN",
        "outputId": "1a2ba108-3b99-4964-fa70-f42c627cfb21"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = hg_pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)"
      ],
      "metadata": {
        "id": "RQzcc173p2GG"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = hg_pipe(prompt, max_new_tokens=128)\n",
        "\n",
        "print(outputs[0][\"generated_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bh-ty6iHp6l7",
        "outputId": "3977db48-193e-466c-b46c-e0c41ed4608c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 09 Feb 2025\n",
            "\n",
            "You are an amazing storyteller. From the following synopsis, create an engaging story.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "a person died in crash while driving home<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "As the sun began to set on a typical Friday evening, John had just finished a long week of work at the office. He had been looking forward to a relaxing night at home, but fate had other plans. As he pulled out of the driveway, his eyes were fixed on the road ahead, his hands gripping the steering wheel tightly as he navigated through the crowded streets.\n",
            "\n",
            "It was a typical Friday evening, with people rushing to get home from work and school, and John was just trying to get to his own house without any major incidents. But as he approached the intersection of Elm and Oak, he failed to notice a pedestrian crossing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\":\"system\", \"content\": \"You are an amazing storyteller. From the following synopsis, create an engaging story in urdu language.\"},\n",
        "    {\"role\": \"user\", \"content\": \"A woman discovers a hidden talent for cooking and starts her own successful restaurant.\"},\n",
        "]\n",
        "prompt = hg_pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "outputs = hg_pipe(prompt, max_new_tokens=128)\n",
        "\n",
        "print(outputs[0][\"generated_text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzAjoUdyp8ui",
        "outputId": "b8d0dc24-a8e3-452c-dde5-3eb440bb14c4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 09 Feb 2025\n",
            "\n",
            "You are an amazing storyteller. From the following synopsis, create an engaging story in urdu language.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "A woman discovers a hidden talent for cooking and starts her own successful restaurant.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "مریم نئی سے ایک خاتون نے ایک مشہور رستہ کھانے کی چھوٹی چھوٹی کھانے کی کھانے کی کوشش کی۔\n",
            "\n",
            "مریم کی پہلی بار اس کی پیدائش ایک گھر میں ہوئی تھی جہاں اس نے اپنے والدین سے کھانے کی کھانے کی کہانی سنی\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GnxbkQonq1L4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}